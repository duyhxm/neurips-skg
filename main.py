"""
Pipeline xá»­ lÃ½ tÃ i liá»‡u há»c thuáº­t báº±ng GROBID vá»›i luá»“ng xá»­ lÃ½ tá»‘i Æ°u.

Pipeline nÃ y cung cáº¥p:
- Xá»­ lÃ½ theo batch vá»›i kháº£ nÄƒng phá»¥c há»“i (resumability)
- TÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng sau má»—i batch
- Theo dÃµi hiá»‡u suáº¥t thá»i gian thá»±c
- Logging mÃ u sáº¯c vÃ  chi tiáº¿t
- Tá»‘i Æ°u hiá»‡u nÄƒng (má»—i PDF chá»‰ táº£i má»™t láº§n duy nháº¥t)
"""

import json
import logging
import threading
import signal
import sys
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Set, Generator, Optional, Tuple, Any, Iterator
from statistics import mean, median
from rich.logging import RichHandler
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn, TimeRemainingColumn
from rich.prompt import Prompt, IntPrompt
import colorama

from grobid_pipeline import client, config, models, parser
from grobid_pipeline.client import GrobidClient
from grobid_pipeline.exceptions import PDFDownloadError, GrobidRequestError

# Global flag Ä‘á»ƒ kiá»ƒm soÃ¡t viá»‡c dá»«ng pipeline
emergency_stop = threading.Event()

# Khá»Ÿi táº¡o rich console
console = Console()

@dataclass
class PerformanceTracker:
    """Theo dÃµi vÃ  tÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ hiá»‡u suáº¥t xá»­ lÃ½."""
    
    success_count: int = 0
    failure_count: int = 0
    processing_times: List[float] = field(default_factory=list)
    author_stats: Dict[str, List[float]] = field(default_factory=lambda: {
        "author_counts": [],
        "affiliation_rates": []
    })
    reference_stats: Dict[str, List[float]] = field(default_factory=lambda: {
        "ref_counts": [],
        "title_rates": [],
        "year_rates": [],
        "venue_rates": []
    })
    
    def record_success(self, process_time: float, result: models.PaperResult) -> None:
        """Ghi nháº­n má»™t lÆ°á»£t xá»­ lÃ½ thÃ nh cÃ´ng cÃ¹ng cÃ¡c thÃ´ng sá»‘ cháº¥t lÆ°á»£ng."""
        self.success_count += 1
        self.processing_times.append(process_time)
        
        # Author stats
        if "grobid_authors" in result and result["grobid_authors"]:
            num_authors = len(result["grobid_authors"])
            if num_authors > 0:
                self.author_stats["author_counts"].append(num_authors)
                aff_count = sum(1 for author in result["grobid_authors"] 
                            if "affiliations" in author and author["affiliations"])
                self.author_stats["affiliation_rates"].append(aff_count / num_authors)
        
        # Reference stats
        if "grobid_references" in result and result["grobid_references"]:
            num_refs = len(result["grobid_references"])
            if num_refs > 0:
                self.reference_stats["ref_counts"].append(num_refs)
                
                # TÃ­nh tá»· lá»‡ cÃ¡c trÆ°á»ng metadata cá»§a reference
                title_rate = sum(1 for ref in result["grobid_references"] if "title" in ref) / num_refs
                year_rate = sum(1 for ref in result["grobid_references"] if "year" in ref) / num_refs
                venue_rate = sum(1 for ref in result["grobid_references"] if "venue" in ref) / num_refs
                
                self.reference_stats["title_rates"].append(title_rate)
                self.reference_stats["year_rates"].append(year_rate)
                self.reference_stats["venue_rates"].append(venue_rate)
    
    def record_failure(self, process_time: float) -> None:
        """Ghi nháº­n má»™t lÆ°á»£t xá»­ lÃ½ tháº¥t báº¡i."""
        self.failure_count += 1
        if process_time > 0:  # Chá»‰ ghi nháº­n náº¿u cÃ³ thá»i gian xá»­ lÃ½ thá»±c
            self.processing_times.append(process_time)
    
    def reset(self) -> None:
        """Reset toÃ n bá»™ cÃ¡c chá»‰ sá»‘ theo dÃµi."""
        self.success_count = 0
        self.failure_count = 0
        self.processing_times.clear()
        self.author_stats = {"author_counts": [], "affiliation_rates": []}
        self.reference_stats = {
            "ref_counts": [], "title_rates": [], 
            "year_rates": [], "venue_rates": []
        }
    
    def get_report(self) -> Dict[str, Any]:
        """Tá»•ng há»£p cÃ¡c chá»‰ sá»‘ thÃ nh bÃ¡o cÃ¡o."""
        total_papers = self.success_count + self.failure_count
        
        # TÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ cÆ¡ báº£n
        report = {
            "total_papers": total_papers,
            "success_count": self.success_count,
            "failure_count": self.failure_count,
            "success_rate": (self.success_count / total_papers * 100) if total_papers else 0
        }
        
        # ThÃªm cÃ¡c chá»‰ sá»‘ thá»i gian
        if self.processing_times:
            total_time = sum(self.processing_times)
            report.update({
                "total_time": total_time,
                "avg_time": mean(self.processing_times),
                "min_time": min(self.processing_times),
                "max_time": max(self.processing_times),
                "papers_per_minute": (total_papers / total_time * 60) if total_time > 0 else 0
            })
        
        # ThÃªm thá»‘ng kÃª vá» Author (náº¿u cÃ³)
        if self.author_stats["author_counts"]:
            report["author_stats"] = {
                "avg_authors_per_paper": mean(self.author_stats["author_counts"]),
                "min_authors": min(self.author_stats["author_counts"]),
                "max_authors": max(self.author_stats["author_counts"]),
                "avg_affiliation_rate": mean(self.author_stats["affiliation_rates"]) * 100
            }
        
        # ThÃªm thá»‘ng kÃª vá» Reference (náº¿u cÃ³)
        if self.reference_stats["ref_counts"]:
            report["reference_stats"] = {
                "avg_refs_per_paper": mean(self.reference_stats["ref_counts"]),
                "min_refs": min(self.reference_stats["ref_counts"]),
                "max_refs": max(self.reference_stats["ref_counts"]),
                "avg_field_rates": {
                    "title": mean(self.reference_stats["title_rates"]) * 100,
                    "year": mean(self.reference_stats["year_rates"]) * 100,
                    "venue": mean(self.reference_stats["venue_rates"]) * 100
                }
            }
        
        return report

    def merge(self, other: 'PerformanceTracker') -> None:
        """Gá»™p dá»¯ liá»‡u tá»« má»™t tracker khÃ¡c vÃ o tracker hiá»‡n táº¡i."""
        self.success_count += other.success_count
        self.failure_count += other.failure_count
        self.processing_times.extend(other.processing_times)
        
        # Gá»™p thá»‘ng kÃª tÃ¡c giáº£
        self.author_stats["author_counts"].extend(other.author_stats["author_counts"])
        self.author_stats["affiliation_rates"].extend(other.author_stats["affiliation_rates"])
        
        # Gá»™p thá»‘ng kÃª trÃ­ch dáº«n
        self.reference_stats["ref_counts"].extend(other.reference_stats["ref_counts"])
        self.reference_stats["title_rates"].extend(other.reference_stats["title_rates"])
        self.reference_stats["year_rates"].extend(other.reference_stats["year_rates"])
        self.reference_stats["venue_rates"].extend(other.reference_stats["venue_rates"])

def setup_logging() -> None:
    """Cáº¥u hÃ¬nh há»‡ thá»‘ng logging vá»›i hai output:
    - Console: CÃ³ mÃ u sáº¯c, level tá»« config
    - File: KhÃ´ng mÃ u, level DEBUG
    """
    # Reset root logger
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    # Cáº¥u hÃ¬nh rich handler cho console
    console_handler = RichHandler(
        rich_tracebacks=True,
        markup=True,
        show_path=False,
        enable_link_path=False,
    )
    console_handler.setLevel(config.LOG_LEVEL)
    console_formatter = logging.Formatter(config.CONSOLE_LOG_FORMAT)
    console_handler.setFormatter(console_formatter)
    
    # Cáº¥u hÃ¬nh file handler
    file_handler = logging.FileHandler(config.LOG_FILE_PATH, encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_formatter = logging.Formatter(config.FILE_LOG_FORMAT)
    file_handler.setFormatter(file_formatter)
    
    # Cáº¥u hÃ¬nh root logger
    logging.root.setLevel(logging.DEBUG)
    logging.root.addHandler(console_handler)
    logging.root.addHandler(file_handler)
    
    logging.info("ÄÃ£ khá»Ÿi táº¡o logging system")

def load_processed_papers() -> Set[str]:
    """
    Táº£i danh sÃ¡ch cÃ¡c paper_id Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ thÃ nh cÃ´ng.
    
    Returns:
        Set[str]: Táº­p há»£p cÃ¡c paper_id Ä‘Ã£ xá»­ lÃ½
    """
    processed_papers = set()
    
    if config.PROGRESS_FILE_PATH.exists():
        try:
            with open(config.PROGRESS_FILE_PATH, 'r', encoding='utf-8') as f:
                processed_papers = set(line.strip() for line in f if line.strip())
            logging.info(f"ÄÃ£ táº£i {len(processed_papers)} paper_id Ä‘Ã£ xá»­ lÃ½ tá»« checkpoint")
        except Exception as e:
            logging.error(f"Lá»—i khi Ä‘á»c file checkpoint: {str(e)}")
    
    return processed_papers

def read_input_file(processed_papers: Set[str]) -> Generator[Tuple[str, str], None, None]:
    """
    Äá»c file JSONL Ä‘áº§u vÃ o vÃ  yield cÃ¡c paper cáº§n xá»­ lÃ½.
    
    Args:
        processed_papers: Táº­p há»£p cÃ¡c paper_id Ä‘Ã£ xá»­ lÃ½
        
    Yields:
        Tuple[str, str]: Má»—i tuple chá»©a (paper_id, pdf_link)
    """
    if not config.INPUT_FILE_PATH.exists():
        logging.error(f"File Ä‘áº§u vÃ o khÃ´ng tá»“n táº¡i: {config.INPUT_FILE_PATH}")
        return
    
    total_count = 0
    skipped_count = 0
    
    with open(config.INPUT_FILE_PATH, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
                
            try:
                paper_data = json.loads(line)
                paper_id = paper_data.get('paper_id')
                pdf_link = paper_data.get('pdf_link')
                
                total_count += 1
                
                # Kiá»ƒm tra xem paper Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ chÆ°a
                if paper_id in processed_papers:
                    skipped_count += 1
                    continue
                    
                if not paper_id or not pdf_link:
                    logging.warning(f"DÃ²ng thiáº¿u paper_id hoáº·c pdf_link: {line[:100]}...")
                    continue
                    
                yield (paper_id, pdf_link)
                
            except json.JSONDecodeError:
                logging.warning(f"DÃ²ng khÃ´ng pháº£i JSON há»£p lá»‡: {line[:100]}...")
    
    logging.info(f"ÄÃ£ Ä‘á»c {total_count} paper tá»« file Ä‘áº§u vÃ o, bá» qua {skipped_count} paper Ä‘Ã£ xá»­ lÃ½")

def mark_paper_as_processed(paper_id: str) -> None:
    """
    ÄÃ¡nh dáº¥u má»™t paper Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ thÃ nh cÃ´ng.
    
    Args:
        paper_id: ID cá»§a paper Ä‘Ã£ xá»­ lÃ½
    """
    try:
        with open(config.PROGRESS_FILE_PATH, 'a', encoding='utf-8') as f:
            f.write(f"{paper_id}\n")
    except Exception as e:
        logging.error(f"Lá»—i khi ghi vÃ o file checkpoint: {str(e)}")

def process_single_paper(grobid_client: GrobidClient, 
                        paper_id: str, 
                        pdf_link: str) -> Tuple[bool, float, models.PaperResult]:
    """
    Xá»­ lÃ½ má»™t paper duy nháº¥t báº±ng GROBID.
    
    Args:
        grobid_client: Client Ä‘á»ƒ gá»i GROBID API
        paper_id: ID cá»§a paper
        pdf_link: URL Ä‘á»ƒ táº£i PDF
        
    Returns:
        Tuple[bool, float, models.PaperResult]:
            - bool: True náº¿u xá»­ lÃ½ hoÃ n toÃ n thÃ nh cÃ´ng
            - float: Thá»i gian xá»­ lÃ½ (giÃ¢y)
            - models.PaperResult: Káº¿t quáº£ xá»­ lÃ½
    """
    start_time = time.time()
    
    # Khá»Ÿi táº¡o Ä‘á»‘i tÆ°á»£ng káº¿t quáº£ vá»›i cÃ¡c giÃ¡ trá»‹ máº·c Ä‘á»‹nh
    result: models.PaperResult = {
        "paper_id": paper_id,
        "processing_status": {
            "header_status": "pending",
            "references_status": "pending"
        }
    }
    
    header_success = False
    references_success = False
    
    try:
        # Gá»i phÆ°Æ¡ng thá»©c má»›i - táº£i PDF má»™t láº§n duy nháº¥t
        header_xml, references_xml = grobid_client.process_paper_from_url(pdf_link, paper_id)
        
        # Parse káº¿t quáº£ XML
        # Parse káº¿t quáº£ XML má»™t cÃ¡ch riÃªng biá»‡t
        authors = parser.parse_header_xml(header_xml, paper_id)
        references = parser.parse_references_xml(references_xml, paper_id)

        # Cáº­p nháº­t káº¿t quáº£
        if authors:
            result["grobid_authors"] = authors
        if references:
            result["grobid_references"] = references

        # Cáº­p nháº­t tráº¡ng thÃ¡i
        result["processing_status"]["header_status"] = "success" if authors else "failed"
        header_success = bool(authors)

        result["processing_status"]["references_status"] = "success" if references else "failed"
        references_success = bool(references)
            
        # Log thÃ nh cÃ´ng á»Ÿ cáº¥p Ä‘á»™ DEBUG thay vÃ¬ INFO Ä‘á»ƒ khÃ´ng hiá»ƒn thá»‹ ra console
        logging.debug(f"âœ… Xá»­ lÃ½ thÃ nh cÃ´ng {paper_id}")
        
    except PDFDownloadError as e:
        error_msg = f"Lá»—i khi táº£i PDF: {str(e)}"
        logging.error(f"âŒ [{paper_id}] {error_msg}")
        result["processing_status"] = {
            "header_status": "failed",
            "references_status": "failed",
            "error_message": error_msg
        }
    except GrobidRequestError as e:
        error_msg = f"Lá»—i khi gá»i GROBID: {str(e)}"
        logging.error(f"âŒ [{paper_id}] {error_msg}")
        result["processing_status"] = {
            "header_status": "failed",
            "references_status": "failed",
            "error_message": error_msg
        }
    except Exception as e:
        error_msg = f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {str(e)}"
        logging.exception(f"âŒ [{paper_id}] {error_msg}")
        result["processing_status"] = {
            "header_status": "failed",
            "references_status": "failed",
            "error_message": error_msg
        }
    
    process_time = time.time() - start_time
    
    # Kiá»ƒm tra xem cÃ³ thÃ nh cÃ´ng hoÃ n toÃ n khÃ´ng
    overall_success = header_success and references_success
    
    return overall_success, process_time, result

def run_pipeline(overall_tracker: PerformanceTracker,
               processed_papers: Set[str],
               num_workers: int = config.MAX_WORKERS,
               batch_size: int = config.BATCH_SIZE) -> None:
    """
    Cháº¡y pipeline xá»­ lÃ½ batch vá»›i kháº£ nÄƒng phá»¥c há»“i vÃ  tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng.
    
    Args:
        overall_tracker: Äá»‘i tÆ°á»£ng theo dÃµi tiáº¿n trÃ¬nh vÃ  hiá»‡u suáº¥t tá»•ng thá»ƒ
        processed_papers: Táº­p há»£p cÃ¡c paper_id Ä‘Ã£ xá»­ lÃ½
        num_workers: Sá»‘ lÆ°á»£ng worker thread
        batch_size: Sá»‘ lÆ°á»£ng paper xá»­ lÃ½ má»—i batch
    """
    # Má»Ÿ file Ä‘áº§u ra á»Ÿ cháº¿ Ä‘á»™ ghi ná»‘i tiáº¿p
    output_file_dir = config.OUTPUT_FILE_PATH.parent
    output_file_dir.mkdir(parents=True, exist_ok=True)
    
    # Khá»Ÿi táº¡o generator
    paper_generator = read_input_file(processed_papers)
    
    # Kiá»ƒm tra xem cÃ³ dá»¯ liá»‡u Ä‘á»ƒ xá»­ lÃ½ khÃ´ng
    papers_to_process = []
    auto_mode = False  # Cháº¿ Ä‘á»™ tá»± Ä‘á»™ng xá»­ lÃ½ táº¥t cáº£ cÃ¡c batch
    
    def process_batch(batch: List[Tuple[str, str]], progress, task_id, batch_tracker: PerformanceTracker) -> None:
        """HÃ m helper Ä‘á»ƒ xá»­ lÃ½ má»™t batch paper."""
        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            futures = []
            
            # Chuáº©n bá»‹ vÃ  submit cÃ¡c task
            for paper_id, pdf_link in batch:
                if emergency_stop.is_set():
                    break
                    
                future = executor.submit(
                    process_single_paper,
                    GrobidClient(
                        config.GROBID_HEADER_URL,
                        config.GROBID_REFERENCES_URL
                    ),
                    paper_id,
                    pdf_link
                )
                futures.append((paper_id, future))
            
            # Thu tháº­p káº¿t quáº£ theo thá»© tá»± hoÃ n thÃ nh
            with open(config.OUTPUT_FILE_PATH, 'a', encoding='utf-8') as out_file:
                for paper_id, future in [(p_id, f) for p_id, f in futures]:
                    if emergency_stop.is_set():
                        break
                        
                    try:
                        success, process_time, result = future.result()
                        
                        # Ghi káº¿t quáº£ vÃ o file Ä‘áº§u ra
                        out_file.write(json.dumps(result, ensure_ascii=False) + '\n')
                        
                        # Cáº­p nháº­t trÃ¬nh theo dÃµi tiáº¿n trÃ¬nh cho batch hiá»‡n táº¡i
                        if success:
                            batch_tracker.record_success(process_time, result)
                            # ÄÃ¡nh dáº¥u paper Ä‘Ã£ xá»­ lÃ½ thÃ nh cÃ´ng
                            mark_paper_as_processed(paper_id)
                        else:
                            batch_tracker.record_failure(process_time)
                            
                        # Cáº­p nháº­t thanh tiáº¿n trÃ¬nh
                        progress.update(task_id, advance=1)
                    except Exception as e:
                        logging.exception(f"Lá»—i khi xá»­ lÃ½ káº¿t quáº£ cho {paper_id}: {str(e)}")
                        progress.update(task_id, advance=1)
    
    # Äá»c batch Ä‘áº§u tiÃªn
    for _ in range(batch_size):
        try:
            paper = next(paper_generator)
            papers_to_process.append(paper)
        except StopIteration:
            break
    
    if not papers_to_process:
        logging.info("KhÃ´ng cÃ²n paper nÃ o cáº§n xá»­ lÃ½")
        return
    
    total_processed = 0
    batch_count = 1
    
    # Tiáº¿p tá»¥c xá»­ lÃ½ tá»«ng batch
    while papers_to_process:
        if emergency_stop.is_set():
            logging.warning("ğŸ›‘ Nháº­n tÃ­n hiá»‡u dá»«ng, Ä‘ang káº¿t thÃºc...")
            break
        
        # Táº¡o tracker riÃªng cho batch hiá»‡n táº¡i
        batch_tracker = PerformanceTracker()
        
        current_batch_size = len(papers_to_process)
        logging.info(f"Báº¯t Ä‘áº§u xá»­ lÃ½ batch {batch_count} vá»›i {current_batch_size} paper")
        
        # Khá»Ÿi táº¡o thanh tiáº¿n trÃ¬nh rich cho batch hiá»‡n táº¡i
        with Progress(
            SpinnerColumn(),
            TextColumn("[bold blue]Processing Batch {task.fields[batch_number]}[/bold blue]"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TextColumn("({task.completed}/{task.total})"),
            TimeElapsedColumn(),
            TimeRemainingColumn(),
            console=console
        ) as progress:
            # ThÃªm task cho batch hiá»‡n táº¡i
            task_id = progress.add_task(
                f"Batch {batch_count}", 
                total=current_batch_size,
                batch_number=batch_count
            )
            
            # Xá»­ lÃ½ batch hiá»‡n táº¡i vá»›i thanh tiáº¿n trÃ¬nh má»›i
            process_batch(papers_to_process, progress, task_id, batch_tracker)
            total_processed += current_batch_size
        
        # In dÃ²ng trá»‘ng Ä‘á»ƒ táº¡o khoáº£ng cÃ¡ch trÆ°á»›c bÃ¡o cÃ¡o
        console.print()
        
        # Gá»™p dá»¯ liá»‡u tá»« batch_tracker vÃ o overall_tracker
        overall_tracker.merge(batch_tracker)
        
        # In bÃ¡o cÃ¡o chi tiáº¿t sau má»—i batch sá»­ dá»¥ng batch_tracker
        report = batch_tracker.get_report()
        display_batch_report(batch_count, report, total_processed)
        
        # Náº¿u khÃ´ng á»Ÿ cháº¿ Ä‘á»™ tá»± Ä‘á»™ng, há»i ngÆ°á»i dÃ¹ng
        if not auto_mode and not emergency_stop.is_set():
            try:
                choice = console.input(
                    "[bold yellow][C]ontinue, [A]uto, [Q]uit: [/bold yellow]"
                ).lower()
                
                if choice == 'q':
                    logging.info("NgÆ°á»i dÃ¹ng chá»n dá»«ng pipeline")
                    emergency_stop.set()
                    break
                elif choice == 'a':
                    auto_mode = True
                    # Hiá»ƒn thá»‹ tÃ¹y chá»n cáº¥u hÃ¬nh cho cháº¿ Ä‘á»™ tá»± Ä‘á»™ng
                    console.print("[bold green]Entering Auto Mode. You can adjust settings for the remainder of the run.[/bold green]")
                    
                    # Há»i Ä‘á»ƒ thay Ä‘á»•i batch_size
                    try:
                        new_batch_size = IntPrompt.ask(
                            f"Enter new batch size for reporting (current: {batch_size}) or press Enter to keep it",
                            default=batch_size
                        )
                        
                        # Há»i Ä‘á»ƒ thay Ä‘á»•i num_workers
                        new_num_workers = IntPrompt.ask(
                            f"Enter new number of workers (current: {num_workers}) or press Enter to keep it",
                            default=num_workers
                        )
                        
                        # Cáº­p nháº­t giÃ¡ trá»‹ náº¿u cÃ³ thay Ä‘á»•i
                        if new_batch_size != batch_size:
                            batch_size = new_batch_size
                        
                        if new_num_workers != num_workers:
                            num_workers = new_num_workers
                        
                        console.print(f"[bold green]Configuration updated. Starting auto mode with batch_size={batch_size}, workers={num_workers}...[/bold green]")
                        logging.info(f"Chuyá»ƒn sang cháº¿ Ä‘á»™ tá»± Ä‘á»™ng vá»›i batch_size={batch_size}, workers={num_workers}")
                    except (KeyboardInterrupt, EOFError):
                        console.print("[bold yellow]Báº¡n Ä‘Ã£ giÃ¡n Ä‘oáº¡n nháº­p liá»‡u. Äang dá»«ng pipeline má»™t cÃ¡ch an toÃ n...[/bold yellow]")
                        emergency_stop.set()
                        break
            except (KeyboardInterrupt, EOFError):
                console.print("[bold yellow]Báº¡n Ä‘Ã£ giÃ¡n Ä‘oáº¡n nháº­p liá»‡u. Äang dá»«ng pipeline má»™t cÃ¡ch an toÃ n...[/bold yellow]")
                emergency_stop.set()
                break
        
        # Chuáº©n bá»‹ batch tiáº¿p theo náº¿u khÃ´ng cÃ³ tÃ­n hiá»‡u dá»«ng
        if not emergency_stop.is_set():
            papers_to_process = []
            for _ in range(batch_size):
                try:
                    paper = next(paper_generator)
                    papers_to_process.append(paper)
                except StopIteration:
                    break
            
            batch_count += 1
        
        # Náº¿u khÃ´ng cÃ²n paper nÃ o Ä‘á»ƒ xá»­ lÃ½
        if not papers_to_process:
            logging.info("ÄÃ£ xá»­ lÃ½ táº¥t cáº£ paper trong danh sÃ¡ch")
            break
    
    # Hiá»ƒn thá»‹ bÃ¡o cÃ¡o tá»•ng káº¿t sá»­ dá»¥ng overall_tracker
    if not emergency_stop.is_set():
        console.print("\n[bold green]ğŸ‰ ÄÃ£ hoÃ n thÃ nh táº¥t cáº£ batch![/bold green]")
        console.print("[bold cyan]ğŸ“Š BÃ¡o cÃ¡o tá»•ng káº¿t[/bold cyan]")
        
        # Láº¥y bÃ¡o cÃ¡o tá»« overall_tracker
        final_report = overall_tracker.get_report()
        display_overall_report(final_report, total_processed)

def display_batch_report(batch_number: int, report: Dict[str, Any], total_processed: int) -> None:
    """
    Hiá»ƒn thá»‹ bÃ¡o cÃ¡o chi tiáº¿t cá»§a má»™t batch.
    
    Args:
        batch_number: Sá»‘ thá»© tá»± cá»§a batch
        report: BÃ¡o cÃ¡o hiá»‡u suáº¥t tá»« PerformanceTracker
        total_processed: Tá»•ng sá»‘ paper Ä‘Ã£ xá»­ lÃ½ Ä‘áº¿n hiá»‡n táº¡i
    """
    # Táº¡o báº£ng bÃ¡o cÃ¡o
    table = Table(title=f"ğŸ“Š BÃ¡o cÃ¡o Batch {batch_number}",
                 show_header=True,
                 header_style="bold blue")
    
    table.add_column("Chá»‰ sá»‘", justify="left")
    table.add_column("GiÃ¡ trá»‹", justify="right")
    
    # ThÃ´ng sá»‘ cÆ¡ báº£n
    table.add_row("Tá»•ng sá»‘ paper", str(report['total_papers']))
    table.add_row("Xá»­ lÃ½ thÃ nh cÃ´ng", str(report['success_count']))
    table.add_row("Xá»­ lÃ½ tháº¥t báº¡i", str(report['failure_count']))
    table.add_row("Tá»· lá»‡ thÃ nh cÃ´ng", f"{report['success_rate']:.1f}%")
    table.add_row("ÄÃ£ xá»­ lÃ½ tá»•ng cá»™ng", str(total_processed))
    
    # ThÃ´ng sá»‘ thá»i gian
    if 'total_time' in report:
        table.add_row("Thá»i gian xá»­ lÃ½ batch", f"{report['total_time']:.1f}s")
        table.add_row("Tá»‘c Ä‘á»™ trung bÃ¬nh", 
                     f"{report.get('papers_per_minute', 0):.1f} papers/phÃºt")
        table.add_row("Thá»i gian trung bÃ¬nh/paper", f"{report.get('avg_time', 0):.2f}s")
    
    # ThÃ´ng sá»‘ vá» Author
    if 'author_stats' in report:
        auth_stats = report['author_stats']
        table.add_row("", "")  # DÃ²ng trá»‘ng Ä‘á»ƒ phÃ¢n tÃ¡ch
        table.add_row("[bold]Thá»‘ng kÃª TÃ¡c giáº£[/bold]", "")
        table.add_row(
            "Sá»‘ tÃ¡c giáº£ trung bÃ¬nh",
            f"{auth_stats['avg_authors_per_paper']:.1f}"
        )
        table.add_row(
            "Sá»‘ tÃ¡c giáº£ tá»‘i thiá»ƒu",
            str(auth_stats.get('min_authors', 'N/A'))
        )
        table.add_row(
            "Sá»‘ tÃ¡c giáº£ tá»‘i Ä‘a",
            str(auth_stats.get('max_authors', 'N/A'))
        )
        table.add_row(
            "Tá»· lá»‡ cÃ³ affiliation",
            f"{auth_stats['avg_affiliation_rate']:.1f}%"
        )
    
    # ThÃ´ng sá»‘ vá» Reference
    if 'reference_stats' in report:
        ref_stats = report['reference_stats']
        table.add_row("", "")  # DÃ²ng trá»‘ng Ä‘á»ƒ phÃ¢n tÃ¡ch
        table.add_row("[bold]Thá»‘ng kÃª Tham chiáº¿u[/bold]", "")
        table.add_row(
            "Sá»‘ tham chiáº¿u trung bÃ¬nh",
            f"{ref_stats['avg_refs_per_paper']:.1f}"
        )
        table.add_row(
            "Sá»‘ tham chiáº¿u tá»‘i thiá»ƒu",
            str(ref_stats.get('min_refs', 'N/A'))
        )
        table.add_row(
            "Sá»‘ tham chiáº¿u tá»‘i Ä‘a",
            str(ref_stats.get('max_refs', 'N/A'))
        )
        
        field_rates = ref_stats['avg_field_rates']
        table.add_row(
            "Tá»· lá»‡ cÃ³ title",
            f"{field_rates['title']:.1f}%"
        )
        table.add_row(
            "Tá»· lá»‡ cÃ³ year",
            f"{field_rates['year']:.1f}%"
        )
        table.add_row(
            "Tá»· lá»‡ cÃ³ venue",
            f"{field_rates['venue']:.1f}%"
        )
    
    # In báº£ng bÃ¡o cÃ¡o
    console.print(table)

def display_overall_report(report: Dict[str, Any], total_processed: int) -> None:
    """
    Hiá»ƒn thá»‹ bÃ¡o cÃ¡o tá»•ng káº¿t cá»§a toÃ n bá»™ quÃ¡ trÃ¬nh xá»­ lÃ½.
    
    Args:
        report: BÃ¡o cÃ¡o hiá»‡u suáº¥t tá»« PerformanceTracker
        total_processed: Tá»•ng sá»‘ paper Ä‘Ã£ xá»­ lÃ½
    """
    # Táº¡o báº£ng bÃ¡o cÃ¡o
    table = Table(title=f"ğŸ“Š BÃ¡o cÃ¡o Tá»•ng káº¿t",
                 show_header=True,
                 header_style="bold blue")
    
    table.add_column("Chá»‰ sá»‘", justify="left")
    table.add_column("GiÃ¡ trá»‹", justify="right")
    
    # ThÃ´ng sá»‘ cÆ¡ báº£n
    table.add_row("Tá»•ng sá»‘ paper", str(report['total_papers']))
    table.add_row("Xá»­ lÃ½ thÃ nh cÃ´ng", str(report['success_count']))
    table.add_row("Xá»­ lÃ½ tháº¥t báº¡i", str(report['failure_count']))
    table.add_row("Tá»· lá»‡ thÃ nh cÃ´ng", f"{report['success_rate']:.1f}%")
    table.add_row("ÄÃ£ xá»­ lÃ½ tá»•ng cá»™ng", str(total_processed))
    
    # ThÃ´ng sá»‘ thá»i gian
    if 'total_time' in report:
        table.add_row("Thá»i gian xá»­ lÃ½ tá»•ng cá»™ng", f"{report['total_time']:.1f}s")
        table.add_row("Tá»‘c Ä‘á»™ trung bÃ¬nh", 
                     f"{report.get('papers_per_minute', 0):.1f} papers/phÃºt")
        table.add_row("Thá»i gian trung bÃ¬nh/paper", f"{report.get('avg_time', 0):.2f}s")
    
    # Thá»‘ng kÃª vá» Author
    if 'author_stats' in report:
        auth_stats = report['author_stats']
        table.add_row("", "")  # DÃ²ng trá»‘ng Ä‘á»ƒ phÃ¢n tÃ¡ch
        table.add_row("[bold]Thá»‘ng kÃª TÃ¡c giáº£[/bold]", "")
        table.add_row(
            "Sá»‘ tÃ¡c giáº£ trung bÃ¬nh",
            f"{auth_stats['avg_authors_per_paper']:.1f}"
        )
        table.add_row(
            "Sá»‘ tÃ¡c giáº£ tá»‘i thiá»ƒu",
            str(auth_stats.get('min_authors', 'N/A'))
        )
        table.add_row(
            "Sá»‘ tÃ¡c giáº£ tá»‘i Ä‘a",
            str(auth_stats.get('max_authors', 'N/A'))
        )
        table.add_row(
            "Tá»· lá»‡ cÃ³ affiliation",
            f"{auth_stats['avg_affiliation_rate']:.1f}%"
        )
    
    # Thá»‘ng kÃª vá» Reference
    if 'reference_stats' in report:
        ref_stats = report['reference_stats']
        table.add_row("", "")  # DÃ²ng trá»‘ng Ä‘á»ƒ phÃ¢n tÃ¡ch
        table.add_row("[bold]Thá»‘ng kÃª Tham chiáº¿u[/bold]", "")
        table.add_row(
            "Sá»‘ tham chiáº¿u trung bÃ¬nh",
            f"{ref_stats['avg_refs_per_paper']:.1f}"
        )
        table.add_row(
            "Sá»‘ tham chiáº¿u tá»‘i thiá»ƒu",
            str(ref_stats.get('min_refs', 'N/A'))
        )
        table.add_row(
            "Sá»‘ tham chiáº¿u tá»‘i Ä‘a",
            str(ref_stats.get('max_refs', 'N/A'))
        )
        
        field_rates = ref_stats['avg_field_rates']
        table.add_row(
            "Tá»· lá»‡ cÃ³ title",
            f"{field_rates['title']:.1f}%"
        )
        table.add_row(
            "Tá»· lá»‡ cÃ³ year",
            f"{field_rates['year']:.1f}%"
        )
        table.add_row(
            "Tá»· lá»‡ cÃ³ venue",
            f"{field_rates['venue']:.1f}%"
        )
    
    # In báº£ng bÃ¡o cÃ¡o
    console.print(table)

def display_configuration() -> None:
    """Hiá»ƒn thá»‹ báº£ng cáº¥u hÃ¬nh hiá»‡n táº¡i."""
    table = Table(title="âš™ï¸ Cáº¥u hÃ¬nh Pipeline",
                show_header=True,
                header_style="bold blue")
    
    table.add_column("Tham sá»‘", justify="left")
    table.add_column("GiÃ¡ trá»‹", justify="left")
    
    table.add_row("Input File", str(config.INPUT_FILE_PATH))
    table.add_row("Output File", str(config.OUTPUT_FILE_PATH))
    table.add_row("Progress File", str(config.PROGRESS_FILE_PATH))
    table.add_row("GROBID URL", config.GROBID_BASE_URL)
    table.add_row("Workers", str(config.MAX_WORKERS))
    table.add_row("Batch Size", str(config.BATCH_SIZE))
    table.add_row("Log Level", str(config.LOG_LEVEL))
    table.add_row("Log File", str(config.LOG_FILE_PATH))
    
    console.print(table)

def main() -> None:
    """HÃ m main vá»›i quy trÃ¬nh Ä‘Æ¡n giáº£n hÆ¡n."""
    # Khá»Ÿi táº¡o mÃ´i trÆ°á»ng
    colorama.init()
    setup_logging()
    
    # ÄÄƒng kÃ½ signal handler
    def signal_handler(signum, frame):
        emergency_stop.set()
        logging.info("ğŸš¦ ÄÃ£ nháº­n tÃ­n hiá»‡u dá»«ng tá»« phÃ­m táº¯t")
    
    # TrÃªn Windows, Æ°u tiÃªn sá»­ dá»¥ng cÃ¡c phÃ­m táº¯t Ã­t phá»• biáº¿n
    # Thá»­ Ä‘Äƒng kÃ½ nhiá»u signal khÃ¡c nhau Ä‘á»ƒ tÃ¬m cÃ¡i hoáº¡t Ä‘á»™ng
    is_handler_registered = False
    
    # Thá»­ vá»›i SIGTERM (cÃ³ thá»ƒ gá»­i báº±ng taskkill /PID process_id /F tá»« command line)
    try:
        signal.signal(signal.SIGTERM, signal_handler)
        is_handler_registered = True
        logging.debug("ÄÃ£ Ä‘Äƒng kÃ½ handler cho SIGTERM")
        console.print("[bold yellow]Äá»ƒ dá»«ng chÆ°Æ¡ng trÃ¬nh, má»Ÿ má»™t terminal khÃ¡c vÃ  cháº¡y 'taskkill /PID <process_id> /F'[/bold yellow]")
    except (AttributeError, ValueError):
        pass
        
    # CÃ¡c phÃ­m táº¯t khÃ¡c váº«n hoáº¡t Ä‘á»™ng thÃ´ng qua KeyboardInterrupt
    # Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n cho ngÆ°á»i dÃ¹ng Ä‘á»ƒ trÃ¡nh nháº§m láº«n
    console.print("[bold yellow]Äá»ƒ thoÃ¡t chÆ°Æ¡ng trÃ¬nh an toÃ n, hÃ£y sá»­ dá»¥ng tÃ¹y chá»n [Q]uit khi Ä‘Æ°á»£c há»i[/bold yellow]")
    
    # Hiá»ƒn thá»‹ banner
    console.print("\n" + "="*60)
    console.print("[bold cyan]ğŸ¤– GROBID PDF Processing Pipeline - Optimized[/bold cyan]")
    console.print("[bold green]Má»—i PDF chá»‰ táº£i má»™t láº§n duy nháº¥t - I/O tá»‘i Æ°u - Resumable[/bold green]")
    console.print("="*60 + "\n")
    
    # Hiá»ƒn thá»‹ cáº¥u hÃ¬nh
    display_configuration()
    
    # XÃ¡c nháº­n vá»›i ngÆ°á»i dÃ¹ng
    choice = console.input("\n[bold yellow][S]tart the pipeline with this configuration, or [Q]uit? [/bold yellow]").lower()
    
    if choice != 's':
        console.print("[bold green]ğŸ‘‹ Táº¡m biá»‡t![/bold green]")
        return
    
    # Reset emergency stop flag
    emergency_stop.clear()
    
    # Táº£i danh sÃ¡ch paper Ä‘Ã£ xá»­ lÃ½
    processed_papers = load_processed_papers()
    
    # Khá»Ÿi táº¡o progress tracker
    tracker = PerformanceTracker()
    
    # Cháº¡y pipeline
    try:
        run_pipeline(tracker, processed_papers)
        
        # Hiá»ƒn thá»‹ thÃ´ng bÃ¡o káº¿t thÃºc
        console.print("[bold green]Pipeline Ä‘Ã£ hoÃ n thÃ nh![/bold green]")
    except (KeyboardInterrupt, EOFError):
        console.print("[bold yellow]ChÆ°Æ¡ng trÃ¬nh Ä‘Ã£ dá»«ng láº¡i theo yÃªu cáº§u. Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ váº«n Ä‘Æ°á»£c lÆ°u.[/bold yellow]")
    except Exception as e:
        logging.exception("âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh trong pipeline")
        console.print(f"[bold red]Lá»—i: {str(e)}[/bold red]")
    
    console.print("[bold green]Pipeline Ä‘Ã£ hoÃ n thÃ nh![/bold green]")

if __name__ == "__main__":
    main()
